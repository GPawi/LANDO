{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthor: Gregor Pfalz\\ngithub: GPawi\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Module within LANDO to aggregate data from the 10,000 itertations for each modeling software\n",
    "\n",
    "Author: Gregor Pfalz\n",
    "github: GPawi\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Undatable\n",
    "class AggDataUndatable(object):\n",
    "    def __init__(self, prep_Undatable, orig_dir, dttp):\n",
    "        \"\"\"\n",
    "        parameters:\n",
    "        @self.prep_Undatable: object containing the variables from the Undatable object from preparation phase\n",
    "        @self.location_UndatableFolder: string containing the location for the Undatable folder that is used by MATLAB/Octave\n",
    "        @self.CoreIDs: list of CoreIDs used within the LANDO environment\n",
    "        @self.orig_dir: original directory, where user excute LANDO\n",
    "        @self.dttp: value 'Yes' or 'No', if reservoir correction took place\n",
    "        \"\"\"\n",
    "        self.prep_Undatable = prep_Undatable\n",
    "        self.location_UndatableFolder = prep_Undatable.location_UndatableFolder\n",
    "        self.CoreIDs = prep_Undatable.coreid_df\n",
    "        self.CoreIDs = self.CoreIDs[1:].reset_index(drop = True)\n",
    "        self.orig_dir = orig_dir\n",
    "        self.dttp = dttp\n",
    "    \n",
    "    def results_agg(self):\n",
    "        \"\"\"\n",
    "        Main function to aggregate data\n",
    "        \n",
    "        returns:\n",
    "        @self.age_model_result_Undatable: dataframe holding the results from the aggregation \n",
    "        @self.Undatable_core_results: iteration results from Undatable with MeasurementID and model name added\n",
    "        \"\"\"\n",
    "        CoreIDs = self.CoreIDs\n",
    "        dttp = self.dttp\n",
    "        self.__age_model_columns = ['measurementid',\n",
    "                                    'modeloutput_median',\n",
    "                                    'modeloutput_mean',\n",
    "                                    'lower_2_sigma',\n",
    "                                    'lower_1_sigma',\n",
    "                                    'upper_1_sigma',\n",
    "                                    'upper_2_sigma',\n",
    "                                    'model_name']\n",
    "        self.age_model_result_Undatable = pd.DataFrame(columns = self.__age_model_columns)\n",
    "        \n",
    "        #### This section reads the individual txt files that are produced by Undatable\n",
    "        os.chdir(fr'{self.orig_dir}/{self.location_UndatableFolder}')\n",
    "        __individual_result_columns = ['measurementid',\n",
    "                                     'modeloutput_median',\n",
    "                                     'modeloutput_mean',\n",
    "                                     'lower_2_sigma',\n",
    "                                     'lower_1_sigma',\n",
    "                                     'upper_1_sigma',\n",
    "                                     'upper_2_sigma']\n",
    "        for i in range(0, len(CoreIDs)):\n",
    "            __individual_result = pd.read_csv(f'{CoreIDs.iloc[i,0]}_admodel.txt',sep = '\\t', \n",
    "                                            header = 1,\n",
    "                                            index_col = False,\n",
    "                                            usecols = [0,1,2,3,4,5,6],\n",
    "                                            names = __individual_result_columns,\n",
    "                                            converters = {'measurementid': str,\n",
    "                                                          'modeloutput_median': np.int64,\n",
    "                                                          'modeloutput_mean': np.int64,\n",
    "                                                          'lower_2_sigma': np.int64,\n",
    "                                                          'lower_1_sigma': np.int64,\n",
    "                                                          'upper_1_sigma': np.int64,\n",
    "                                                          'upper_2_sigma': np.int64}\n",
    "                                           )\n",
    "            __individual_result['measurementid'] = __individual_result['measurementid'].str.replace('.000000', '')\n",
    "            __individual_result['measurementid'] = __individual_result['measurementid'].str.replace('00000', '')\n",
    "            __individual_result['measurementid'] = __individual_result['measurementid'].str.replace('0000', '')\n",
    "            __individual_result['measurementid'] = CoreIDs.iloc[i,0] + ' ' + __individual_result['measurementid']\n",
    "            __individual_result.insert(7, 'model_name', 'Undatable', True)\n",
    "            __individual_result.insert(8, 'preselection', dttp, True)\n",
    "            self.age_model_result_Undatable = self.age_model_result_Undatable.append(__individual_result)\n",
    "        \n",
    "        self.age_model_result_Undatable = self.age_model_result_Undatable.reset_index(drop = True)\n",
    "        \n",
    "        #### This section loads the iteration results from the additional .mat file into the variable\n",
    "        self.Undatable_core_results = pd.DataFrame()\n",
    "        for i in range(0, len(CoreIDs)):\n",
    "            __load_temp_age = sio.loadmat(f'{CoreIDs.iloc[i,0]}_temage.mat')\n",
    "            __individual_temp_age = pd.DataFrame(__load_temp_age['tempage'])\n",
    "            __individual_temp_age = __individual_temp_age.assign(model_name = 'Undatable')\n",
    "            self.Undatable_core_results = self.Undatable_core_results.append(__individual_temp_age)\n",
    "        self.Undatable_core_results = self.Undatable_core_results.reset_index(drop = True)\n",
    "        self.Undatable_core_results = self.Undatable_core_results.assign(measurementid = self.age_model_result_Undatable['measurementid'])\n",
    "            \n",
    "#### Bchron  \n",
    "class AggDataBchron(object):\n",
    "    def __init__(self, Bchron_core_results, dttp):\n",
    "        \"\"\"\n",
    "        parameters:\n",
    "        @self.Bchron_core_results: dataframe with 10,000 iteration results from Bchron\n",
    "        @self.dttp: value 'Yes' or 'No', if reservoir correction took place\n",
    "        \"\"\"\n",
    "        self.Bchron_core_results = Bchron_core_results\n",
    "        self.dttp = dttp\n",
    "    \n",
    "    def __confidence_intervals(self, g):\n",
    "        \"\"\"\n",
    "        Helper function to get basic statistics (median, mean, 1-sigma range, 2-sigma range)\n",
    "        \n",
    "        returns:\n",
    "        @median: median value of input data\n",
    "        @mean:  mean value of input data\n",
    "        @two_sigma_lo: lower boundary value of 2-sigma range of input data\n",
    "        @one_sigma_lo: lower boundary value of 1-sigma range of input data\n",
    "        @one_sigma_hi: upper boundary value of 1-sigma range of input data\n",
    "        @two_sigma_hi: upper boundary value of 2-sigma range of input data\n",
    "        \"\"\"\n",
    "        median = g.median()\n",
    "        mean = g.mean()\n",
    "        two_sigma_hi = g.quantile(q = 0.954, interpolation = 'nearest') \n",
    "        two_sigma_lo = g.quantile(q = 0.046, interpolation = 'nearest')\n",
    "        one_sigma_hi = g.quantile(q = 0.683, interpolation = 'nearest') \n",
    "        one_sigma_lo = g.quantile(q = 0.317, interpolation = 'nearest')\n",
    "        return median, mean, two_sigma_lo, one_sigma_lo, one_sigma_hi, two_sigma_hi\n",
    "    \n",
    "    def __sort_data(self, data):\n",
    "        \"\"\"\n",
    "        Helper function to sort MeasurementID\n",
    "        \n",
    "        returns:\n",
    "        @data: dataframe with sorted MeasurementID, where composite depth is sorted numeric not as string\n",
    "        \"\"\"\n",
    "        data[['coreid','compositedepth']] = data['measurementid'].str.split(' ', n = 1, expand = True)\n",
    "        data = data.astype(dtype = {'compositedepth' : float}).sort_values(by = ['coreid','compositedepth'], ignore_index = True)\n",
    "        data.drop(['compositedepth','coreid'], axis = 1, inplace = True)\n",
    "        return data \n",
    "    \n",
    "    def results_agg(self):\n",
    "        \"\"\"\n",
    "        Main function to aggregate data\n",
    "        \n",
    "        returns:\n",
    "        @self.age_model_result_Bchron: dataframe holding the results from the aggregation \n",
    "        @self.Bchron_core_results: altered 10,000 iteration results from Bchron with MeasurementID and model name added\n",
    "        \"\"\"\n",
    "        Bchron_core_results = self.Bchron_core_results\n",
    "        dttp = self.dttp\n",
    "        self.age_model_result_Bchron = Bchron_core_results.apply(self.__confidence_intervals, axis = 1, result_type='expand')\n",
    "        self.age_model_result_Bchron.columns = ['modeloutput_median',\n",
    "                                           'modeloutput_mean',\n",
    "                                           'lower_2_sigma',\n",
    "                                           'lower_1_sigma',\n",
    "                                           'upper_1_sigma',\n",
    "                                           'upper_2_sigma']\n",
    "        self.age_model_result_Bchron = self.age_model_result_Bchron.astype(int)\n",
    "        self.age_model_result_Bchron = self.age_model_result_Bchron.reset_index()\n",
    "        self.age_model_result_Bchron = self.age_model_result_Bchron.rename(columns={\"index\": \"measurementid\"})\n",
    "        self.age_model_result_Bchron = self.__sort_data(self.age_model_result_Bchron)\n",
    "        self.age_model_result_Bchron.insert(7, 'model_name', 'Bchron', True)\n",
    "        self.age_model_result_Bchron.insert(8, 'preselection', dttp, True)\n",
    "        ###\n",
    "        self.Bchron_core_results.reset_index(inplace = True)\n",
    "        self.Bchron_core_results['model_name'] = 'Bchron'\n",
    "        self.Bchron_core_results.rename(columns={\"index\": \"measurementid\"}, inplace = True)\n",
    "\n",
    "#### hamstr     \n",
    "class AggDataHamstr(object):\n",
    "    def __init__(self, hamstr_core_results, dttp):\n",
    "        \"\"\"\n",
    "        parameters:\n",
    "        @self.hamstr_core_results: dataframe with 10,000 iteration results from hamstr\n",
    "        @self.dttp: value 'Yes' or 'No', if reservoir correction took place\n",
    "        \"\"\"\n",
    "        self.hamstr_core_results = hamstr_core_results\n",
    "        self.dttp = dttp\n",
    "    \n",
    "    def __confidence_intervals(self, g):\n",
    "        \"\"\"\n",
    "        Helper function to get basic statistics (median, mean, 1-sigma range, 2-sigma range)\n",
    "        \n",
    "        returns:\n",
    "        @median: median value of input data\n",
    "        @mean:  mean value of input data\n",
    "        @two_sigma_lo: lower boundary value of 2-sigma range of input data\n",
    "        @one_sigma_lo: lower boundary value of 1-sigma range of input data\n",
    "        @one_sigma_hi: upper boundary value of 1-sigma range of input data\n",
    "        @two_sigma_hi: upper boundary value of 2-sigma range of input data\n",
    "        \"\"\"\n",
    "        median = g.median()\n",
    "        mean = g.mean()\n",
    "        two_sigma_hi = g.quantile(q = 0.954, interpolation = 'nearest') \n",
    "        two_sigma_lo = g.quantile(q = 0.046, interpolation = 'nearest')\n",
    "        one_sigma_hi = g.quantile(q = 0.683, interpolation = 'nearest') \n",
    "        one_sigma_lo = g.quantile(q = 0.317, interpolation = 'nearest')\n",
    "        return median, mean, two_sigma_lo, one_sigma_lo, one_sigma_hi, two_sigma_hi\n",
    "    \n",
    "    def __sort_data(self, data):\n",
    "        \"\"\"\n",
    "        Helper function to sort MeasurementID\n",
    "        \n",
    "        returns:\n",
    "        @data: dataframe with sorted MeasurementID, where composite depth is sorted numeric not as string\n",
    "        \"\"\"\n",
    "        data[['coreid','compositedepth']] = data['measurementid'].str.split(' ', n = 1, expand = True)\n",
    "        data = data.astype(dtype = {'compositedepth' : float}).sort_values(by = ['coreid','compositedepth'], ignore_index = True)\n",
    "        data.drop(['compositedepth','coreid'], axis = 1, inplace = True)\n",
    "        return data \n",
    "    \n",
    "    def results_agg(self):\n",
    "        \"\"\"\n",
    "        Main function to aggregate data\n",
    "        \n",
    "        returns:\n",
    "        @self.age_model_result_hamstr: dataframe holding the results from the aggregation \n",
    "        @self.hamstr_core_results: altered 10,000 iteration results from hamstr with MeasurementID and model name added\n",
    "        \"\"\"\n",
    "        hamstr_core_results = self.hamstr_core_results\n",
    "        hamstr_core_results.set_index('depth', inplace = True)\n",
    "        hamstr_core_results.rename_axis('index', inplace = True)\n",
    "        hamstr_core_results.dropna(axis = 0, inplace = True)\n",
    "        dttp = self.dttp\n",
    "        self.age_model_result_hamstr = hamstr_core_results.apply(self.__confidence_intervals, axis = 1, result_type='expand')\n",
    "        self.age_model_result_hamstr.columns = ['modeloutput_median',\n",
    "                                           'modeloutput_mean',\n",
    "                                           'lower_2_sigma',\n",
    "                                           'lower_1_sigma',\n",
    "                                           'upper_1_sigma',\n",
    "                                           'upper_2_sigma']\n",
    "        self.age_model_result_hamstr = self.age_model_result_hamstr.astype(int)\n",
    "        self.age_model_result_hamstr = self.age_model_result_hamstr.reset_index()\n",
    "        self.age_model_result_hamstr = self.age_model_result_hamstr.rename(columns={\"index\": \"measurementid\"})\n",
    "        self.age_model_result_hamstr = self.__sort_data(self.age_model_result_hamstr)\n",
    "        self.age_model_result_hamstr.insert(7, 'model_name', 'hamstr', True)\n",
    "        self.age_model_result_hamstr.insert(8, 'preselection', dttp, True)\n",
    "        ###\n",
    "        self.hamstr_core_results.reset_index(inplace = True)\n",
    "        self.hamstr_core_results = self.hamstr_core_results.rename(columns={\"index\": \"measurementid\"})\n",
    "        self.hamstr_core_results = self.__sort_data(self.hamstr_core_results)\n",
    "        self.hamstr_core_results['model_name'] = 'hamstr'\n",
    "\n",
    "#### Bacon\n",
    "class AggDataBacon(object):\n",
    "    def __init__(self, Bacon_core_results, dttp):\n",
    "        \"\"\"\n",
    "        parameters:\n",
    "        @self.Bacon_core_results: dataframe with 10,000 iteration results from Bacon\n",
    "        @self.dttp: value 'Yes' or 'No', if reservoir correction took place\n",
    "        \"\"\"\n",
    "        self.Bacon_core_results = Bacon_core_results\n",
    "        self.dttp = dttp\n",
    "    \n",
    "    def __confidence_intervals(self, g):\n",
    "        \"\"\"\n",
    "        Helper function to get basic statistics (median, mean, 1-sigma range, 2-sigma range)\n",
    "        \n",
    "        returns:\n",
    "        @median: median value of input data\n",
    "        @mean:  mean value of input data\n",
    "        @two_sigma_lo: lower boundary value of 2-sigma range of input data\n",
    "        @one_sigma_lo: lower boundary value of 1-sigma range of input data\n",
    "        @one_sigma_hi: upper boundary value of 1-sigma range of input data\n",
    "        @two_sigma_hi: upper boundary value of 2-sigma range of input data\n",
    "        \"\"\"\n",
    "        median = g.median()\n",
    "        mean = g.mean()\n",
    "        two_sigma_hi = g.quantile(q = 0.954, interpolation = 'nearest') \n",
    "        two_sigma_lo = g.quantile(q = 0.046, interpolation = 'nearest')\n",
    "        one_sigma_hi = g.quantile(q = 0.683, interpolation = 'nearest') \n",
    "        one_sigma_lo = g.quantile(q = 0.317, interpolation = 'nearest')\n",
    "        return median, mean, two_sigma_lo, one_sigma_lo, one_sigma_hi, two_sigma_hi\n",
    "    \n",
    "    def __sort_data(self, data):\n",
    "        \"\"\"\n",
    "        Helper function to sort MeasurementID\n",
    "        \n",
    "        returns:\n",
    "        @data: dataframe with sorted MeasurementID, where composite depth is sorted numeric not as string\n",
    "        \"\"\"\n",
    "        data[['coreid','compositedepth']] = data['measurementid'].str.split(' ', n = 1, expand = True)\n",
    "        data = data.astype(dtype = {'compositedepth' : float}).sort_values(by = ['coreid','compositedepth'], ignore_index = True)\n",
    "        data.drop(['compositedepth','coreid'], axis = 1, inplace = True)\n",
    "        return data \n",
    "    \n",
    "    def results_agg(self):\n",
    "        \"\"\"\n",
    "        Main function to aggregate data\n",
    "        \n",
    "        returns:\n",
    "        @self.age_model_result_Bacon: dataframe holding the results from the aggregation \n",
    "        @self.Bacon_core_results: altered 10,000 iteration results from Bacon with MeasurementID and model name added\n",
    "        \"\"\"\n",
    "        Bacon_core_results = self.Bacon_core_results\n",
    "        Bacon_core_results.set_index('depth', inplace = True)\n",
    "        Bacon_core_results.rename_axis('index', inplace = True)\n",
    "        Bacon_core_results.dropna(axis = 0, inplace = True)\n",
    "        dttp = self.dttp\n",
    "        self.age_model_result_Bacon = Bacon_core_results.apply(self.__confidence_intervals, axis = 1, result_type='expand')\n",
    "        self.age_model_result_Bacon.columns = ['modeloutput_median',\n",
    "                                           'modeloutput_mean',\n",
    "                                           'lower_2_sigma',\n",
    "                                           'lower_1_sigma',\n",
    "                                           'upper_1_sigma',\n",
    "                                           'upper_2_sigma']\n",
    "        self.age_model_result_Bacon = self.age_model_result_Bacon.astype(int)\n",
    "        self.age_model_result_Bacon = self.age_model_result_Bacon.reset_index()\n",
    "        self.age_model_result_Bacon = self.age_model_result_Bacon.rename(columns={\"index\": \"measurementid\"})\n",
    "        self.age_model_result_Bacon = self.__sort_data(self.age_model_result_Bacon)\n",
    "        self.age_model_result_Bacon.insert(7, 'model_name', 'Bacon', True)\n",
    "        self.age_model_result_Bacon.insert(8, 'preselection', dttp, True)\n",
    "        ###\n",
    "        self.Bacon_core_results.reset_index(inplace = True)\n",
    "        self.Bacon_core_results = self.Bacon_core_results.rename(columns={\"index\": \"measurementid\"})\n",
    "        self.Bacon_core_results = self.__sort_data(self.Bacon_core_results)\n",
    "        self.Bacon_core_results['model_name'] = 'Bacon'       \n",
    "            \n",
    "#### Clam\n",
    "class AggDataClam(object):\n",
    "    def __init__(self, clam_core_results, dttp):\n",
    "        \"\"\"\n",
    "        parameters:\n",
    "        @self.clam_core_results: dataframe with 10,000 iteration results from clam\n",
    "        @self.dttp: value 'Yes' or 'No', if reservoir correction took place\n",
    "        \"\"\"\n",
    "        self.clam_core_results = clam_core_results\n",
    "        self.dttp = dttp\n",
    "    \n",
    "    def __confidence_intervals(self, g):\n",
    "        \"\"\"\n",
    "        Helper function to get basic statistics (median, mean, 1-sigma range, 2-sigma range)\n",
    "        \n",
    "        returns:\n",
    "        @median: median value of input data\n",
    "        @mean:  mean value of input data\n",
    "        @two_sigma_lo: lower boundary value of 2-sigma range of input data\n",
    "        @one_sigma_lo: lower boundary value of 1-sigma range of input data\n",
    "        @one_sigma_hi: upper boundary value of 1-sigma range of input data\n",
    "        @two_sigma_hi: upper boundary value of 2-sigma range of input data\n",
    "        \"\"\"\n",
    "        median = g.median()\n",
    "        mean = g.mean()\n",
    "        two_sigma_hi = g.quantile(q = 0.954, interpolation = 'nearest') \n",
    "        two_sigma_lo = g.quantile(q = 0.046, interpolation = 'nearest')\n",
    "        one_sigma_hi = g.quantile(q = 0.683, interpolation = 'nearest') \n",
    "        one_sigma_lo = g.quantile(q = 0.317, interpolation = 'nearest')\n",
    "        return median, mean, two_sigma_lo, one_sigma_lo, one_sigma_hi, two_sigma_hi\n",
    "    \n",
    "    def results_agg(self):\n",
    "        \"\"\"\n",
    "        Main function to aggregate data\n",
    "        \n",
    "        returns:\n",
    "        @self.age_model_result_clam: dataframe holding the results from the aggregation \n",
    "        @self.clam_core_results: altered iterations from clam with MeasurementID and model name added\n",
    "        \"\"\"\n",
    "        clam_core_results = self.clam_core_results\n",
    "        dttp = self.dttp\n",
    "        if clam_core_results is None: #### This checks if there are results from clam\n",
    "            clam_core_results = []\n",
    "            self.age_model_result_clam = []\n",
    "            print ('No age data available!')\n",
    "        else:\n",
    "            self.age_model_result_clam = clam_core_results.apply(self.__confidence_intervals, axis = 1, result_type='expand')\n",
    "            self.age_model_result_clam.columns = ['modeloutput_median',\n",
    "                                               'modeloutput_mean',\n",
    "                                               'lower_2_sigma',\n",
    "                                               'lower_1_sigma',\n",
    "                                               'upper_1_sigma',\n",
    "                                               'upper_2_sigma']\n",
    "            self.age_model_result_clam = self.age_model_result_clam.astype(int)\n",
    "            self.age_model_result_clam = self.age_model_result_clam.reset_index()\n",
    "            self.age_model_result_clam = self.age_model_result_clam.rename(columns={\"index\": \"measurementid\"})\n",
    "            #### This transforms the clam-specific MeasurementID into it's components\n",
    "            self.age_model_result_clam[['coreid','depth_model_type']] = self.age_model_result_clam['measurementid'].str.split(' ', n = 1, expand = True)\n",
    "            self.age_model_result_clam[['depth','model_name']] = self.age_model_result_clam['depth_model_type'].str.split('-', n = 1, expand = True)\n",
    "            self.age_model_result_clam['model_name'] = self.age_model_result_clam['model_name'].str.replace('_',' ')\n",
    "            self.age_model_result_clam.insert(8, 'preselection', dttp, True)\n",
    "            self.age_model_result_clam['measurementid'] = self.age_model_result_clam['coreid'] + ' ' + self.age_model_result_clam['depth']\n",
    "            self.age_model_result_clam = self.age_model_result_clam.astype(dtype = {'depth' : float}).sort_values(by = ['coreid','depth','model_name'], ignore_index = True)\n",
    "            self.age_model_result_clam.drop(['coreid','depth','depth_model_type'], axis = 1, inplace = True)\n",
    "            self.age_model_result_clam.reset_index(drop = True, inplace = True)\n",
    "            self.age_model_result_clam = self.age_model_result_clam.reindex(['measurementid','modeloutput_median','modeloutput_mean',\n",
    "                                                                             'lower_2_sigma','lower_1_sigma','upper_1_sigma','upper_2_sigma',\n",
    "                                                                             'model_name', 'preselection'], axis = 1)\n",
    "            #### This section checks if there were multiple results from clam\n",
    "            multiple_entries = {}\n",
    "            for i, r in self.age_model_result_clam.iterrows():\n",
    "                if i == 0:\n",
    "                    pass\n",
    "                else:\n",
    "                    if (self.age_model_result_clam.at[(i-1), 'measurementid'].split(' ')[0] == self.age_model_result_clam.at[i, 'measurementid'].split(' ')[0]) \\\n",
    "                    and (self.age_model_result_clam.at[(i-1), 'model_name'] != self.age_model_result_clam.at[i, 'model_name']):\n",
    "                        multiple_entries_coreid = self.age_model_result_clam.at[i, 'measurementid'].split(' ')[0]\n",
    "                        multiple_entries[multiple_entries_coreid] = self.age_model_result_clam[self.age_model_result_clam.measurementid.str.contains(multiple_entries_coreid)]\n",
    "            \n",
    "            #### If there multiple entries, they are treated as one and statistics will be calculated from all results (10,000+)\n",
    "            if bool(multiple_entries) == False:\n",
    "                self.clam_core_results.reset_index(drop = True, inplace = True)\n",
    "                self.clam_core_results['model_name'] = 'clam'\n",
    "                self.clam_core_results['measurementid'] = self.age_model_result_clam['measurementid']\n",
    "            else:\n",
    "                list_of_keys = [*multiple_entries]\n",
    "                new_combined_result_list = []\n",
    "                for key in multiple_entries.keys():\n",
    "                    combined_results = []\n",
    "                    for unique_model_name in multiple_entries[key].model_name.unique():\n",
    "                        combined_results.append(multiple_entries[key][multiple_entries[key].model_name.str.contains(unique_model_name)].reset_index(drop = True))\n",
    "                    combined_results_df = pd.concat(combined_results, axis = 1)\n",
    "                    index_results_df = combined_results_df['measurementid'].dropna(axis = 1)\n",
    "                    index_results_df = index_results_df.loc[:,~index_results_df.columns.duplicated()]['measurementid']\n",
    "                    combined_results_df = combined_results_df.set_index(index_results_df)\n",
    "                    combined_results_df.drop(['measurementid','model_name'],axis = 1, inplace = True)\n",
    "                    new_combined_results = pd.DataFrame(columns = ['measurementid', 'modeloutput_median', 'modeloutput_mean', 'lower_2_sigma',\n",
    "                       'lower_1_sigma', 'upper_1_sigma', 'upper_2_sigma', 'model_name', 'preselection'])\n",
    "                    new_combined_results['measurementid'] = index_results_df\n",
    "                    new_combined_results['model_name'] = 'clam combined'\n",
    "                    for column in combined_results_df.columns.unique():\n",
    "                        if column == 'preselection':\n",
    "                            new_combined_results['preselection'] = combined_results_df['preselection'].dropna(axis = 1).values\n",
    "                        else:\n",
    "                            new_combined_results[f'{column}'] = combined_results_df[f'{column}'].mean(axis = 1).values\n",
    "                    new_combined_result_list.append(new_combined_results)\n",
    "                new_combined_result_df = pd.concat(new_combined_result_list, axis = 0)\n",
    "                self.age_model_result_clam = pd.concat([self.age_model_result_clam[~self.age_model_result_clam.measurementid.str.contains('|'.join(list_of_keys))], new_combined_result_df], axis = 0)\n",
    "                self.age_model_result_clam.reset_index(drop = True, inplace = True)\n",
    "                ###\n",
    "                self.clam_core_results.reset_index(inplace = True)\n",
    "                self.clam_core_results = self.clam_core_results.rename(columns={\"index\": \"measurementid\"})\n",
    "                self.clam_core_results[['coreid','depth_model_type']] = self.clam_core_results['measurementid'].str.split(' ', n = 1, expand = True)\n",
    "                self.clam_core_results[['depth','model_name']] = self.clam_core_results['depth_model_type'].str.split('-', n = 1, expand = True)\n",
    "                self.clam_core_results['model_name'] = self.clam_core_results['model_name'].str.replace('_',' ')\n",
    "                self.clam_core_results['measurementid'] = self.clam_core_results['coreid'] + ' ' + self.clam_core_results['depth']\n",
    "                self.clam_core_results.drop(['coreid','depth','depth_model_type'], axis = 1, inplace = True)\n",
    "                new_combined_result_list = []\n",
    "                for key in multiple_entries.keys():\n",
    "                    combined_results = []\n",
    "                    for unique_model_name in multiple_entries[key].model_name.unique():\n",
    "                        combined_results.append(self.clam_core_results[(self.clam_core_results.measurementid.str.contains(key))&(self.clam_core_results.model_name.str.contains(unique_model_name))].reset_index(drop = True))\n",
    "                    combined_results_df = pd.concat(combined_results, axis = 1)\n",
    "                    index_results_df = combined_results_df['measurementid'].dropna(axis = 1)\n",
    "                    index_results_df = index_results_df.loc[:,~index_results_df.columns.duplicated()]['measurementid']\n",
    "                    combined_results_df = combined_results_df.set_index(index_results_df)\n",
    "                    combined_results_df.drop(['measurementid','model_name'],axis = 1, inplace = True) \n",
    "                    combined_results_df.columns = [f'V{i}' for i in range(1,len(combined_results_df.columns)+1)]\n",
    "                    combined_results_df.reset_index(inplace = True)\n",
    "                    combined_results_df['model_name'] = 'clam combined'\n",
    "                    new_combined_result_list.append(combined_results_df)\n",
    "                new_combined_result_df = pd.concat(new_combined_result_list, axis = 0)\n",
    "                self.clam_core_results = pd.concat([self.clam_core_results[~self.clam_core_results.measurementid.str.contains('|'.join(list_of_keys))], new_combined_result_df], axis = 0)\n",
    "                self.clam_core_results['model_name'] = 'clam'   \n",
    "\n",
    "#### Reservoir\n",
    "class AggDataReservoir(object):\n",
    "    def __init__(self, results, surface_dates, verbose = 0):\n",
    "        \"\"\"\n",
    "        parameters:\n",
    "        @self.reservoir_core_results: dataframe with iteration results from quick calculating modeling software for uppermost layer\n",
    "        @self.surface_dates: dataframe with surfaces dates for each CoreID, which corresponds to expedition year\n",
    "        @self.verbose: If set to 1, messages will be printed whether an adjustment was not necessary; default value: 0\n",
    "        \"\"\"\n",
    "        self.reservoir_core_results = results\n",
    "        self.surface_dates = surface_dates\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def __confidence_intervals(self, g):\n",
    "        \"\"\"\n",
    "        Helper function to get basic statistics (median, mean, 1-sigma range, 2-sigma range)\n",
    "        \n",
    "        returns:\n",
    "        @median: median value of input data\n",
    "        @mean:  mean value of input data\n",
    "        @two_sigma_lo: lower boundary value of 2-sigma range of input data\n",
    "        @one_sigma_lo: lower boundary value of 1-sigma range of input data\n",
    "        @one_sigma_hi: upper boundary value of 1-sigma range of input data\n",
    "        @two_sigma_hi: upper boundary value of 2-sigma range of input data\n",
    "        \"\"\"\n",
    "        median = g.median()\n",
    "        mean = g.mean()\n",
    "        two_sigma_hi = g.quantile(q = 0.954, interpolation = 'nearest') \n",
    "        two_sigma_lo = g.quantile(q = 0.046, interpolation = 'nearest')\n",
    "        one_sigma_hi = g.quantile(q = 0.683, interpolation = 'nearest') \n",
    "        one_sigma_lo = g.quantile(q = 0.317, interpolation = 'nearest')\n",
    "        return median, mean, two_sigma_lo, one_sigma_lo, one_sigma_hi, two_sigma_hi\n",
    "    \n",
    "    def results_agg(self):\n",
    "        \"\"\"\n",
    "        Main function to aggregate data for uppermost layer and compare it to desired target year\n",
    "        \n",
    "        returns:\n",
    "        @self.reservoir_values: dictionary with reservoir value and its error indexed by CoreID \n",
    "        \"\"\"\n",
    "        #### This section aggregates the iteration results and calculates basic statistics\n",
    "        reservoir_core_results = self.reservoir_core_results\n",
    "        verbose = self.verbose\n",
    "        surface_dates = self.surface_dates\n",
    "        reservoir_core_results.set_index('depth', inplace = True)\n",
    "        reservoir_core_results.rename_axis('index', inplace = True)\n",
    "        reservoir_core_results.dropna(axis = 0, inplace = True)\n",
    "        self.age_model_result_reservoir = reservoir_core_results.apply(self.__confidence_intervals, axis = 1, result_type='expand')\n",
    "        self.age_model_result_reservoir.columns = ['modeloutput_median',\n",
    "                                           'modeloutput_mean',\n",
    "                                           'lower_2_sigma',\n",
    "                                           'lower_1_sigma',\n",
    "                                           'upper_1_sigma',\n",
    "                                           'upper_2_sigma']\n",
    "        self.age_model_result_reservoir = self.age_model_result_reservoir.astype(int)\n",
    "        self.age_model_result_reservoir = self.age_model_result_reservoir.reset_index()\n",
    "        self.age_model_result_reservoir = self.age_model_result_reservoir.rename(columns={\"index\": \"measurementid\"})\n",
    "        self.age_model_result_reservoir.insert(7, 'model_name', 'ReservoirCalculation', True)\n",
    "        ####\n",
    "        surface_comparison = surface_dates.merge(self.age_model_result_reservoir, on = ['measurementid'])\n",
    "        surface_comparison = surface_comparison.astype(dtype = {'age': int,\n",
    "                                                                'modeloutput_median': int,\n",
    "                                                                'lower_2_sigma': int,\n",
    "                                                                'upper_2_sigma': int})\n",
    "        #### Compare calculated statistics with desired values and calculates the possible reservoir value\n",
    "        self.reservoir_values = {}\n",
    "        for i,r in surface_comparison.iterrows():\n",
    "            if surface_comparison.at[i, 'modeloutput_mean'] <= surface_comparison.at[i, 'age']:\n",
    "                if verbose == 1:\n",
    "                    print(f\"No adjustment needed for {surface_comparison.at[i, 'coreid']}\")\n",
    "                else:\n",
    "                    pass\n",
    "            elif surface_comparison.at[i, 'lower_2_sigma'] <= surface_comparison.at[i, 'age']:\n",
    "                if verbose == 1:\n",
    "                    print(f\"No adjustment needed for {surface_comparison.at[i, 'coreid']}\")\n",
    "                else:\n",
    "                    pass\n",
    "            elif (surface_comparison.at[i, 'lower_2_sigma']/surface_comparison.at[i, 'age']) > 0.1:\n",
    "                if verbose == 1:\n",
    "                    print(f\"No adjustment needed for {surface_comparison.at[i, 'coreid']}\")\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                R_age_value = surface_comparison.at[i, 'age'] + surface_comparison.at[i, 'modeloutput_mean']\n",
    "                left_error = surface_comparison.at[i,'modeloutput_mean'] - surface_comparison.at[i,'lower_2_sigma']\n",
    "                right_error = surface_comparison.at[i,'upper_2_sigma'] - surface_comparison.at[i,'modeloutput_mean']\n",
    "                if left_error == right_error:\n",
    "                    R_error_value = left_error\n",
    "                elif left_error > right_error:\n",
    "                    R_error_value = left_error\n",
    "                else:\n",
    "                    R_error_value = right_error\n",
    "                self.reservoir_values[surface_comparison.at[i, 'coreid']] = [R_age_value, R_error_value]\n",
    "                print(f\"Reservoir value of {R_age_value} years and an error of {R_error_value} years was calculated for {surface_comparison.at[i, 'coreid']} \")\n",
    "        \n",
    "    def add_reservoir(self, all_ages, which = None):\n",
    "        \"\"\"\n",
    "        Main function to either add reservoir values to all data points, to only bulk samples or disregard the results \n",
    "        \n",
    "        parameters:\n",
    "        @self.all_ages: dataframe with all age determination data\n",
    "        @self.which: string either 'all' (for 'all samples'), 'bulk' (for 'only bulk samples'), or 'without' ('if no reservoir values should be added'); default value: None\n",
    "        \n",
    "        returns:\n",
    "        @self.all_ages: altered dataframe with all age determiantion data plus added reservoir values\n",
    "        \"\"\"\n",
    "        self.all_ages = all_ages\n",
    "        if which is None:\n",
    "            self.which = input(\"Would you like to add the reservoir values to all samples ('all'), to only bulk samples ('bulk'), or disregard the values ('without')? \")\n",
    "        ####\n",
    "        if which == 'all':\n",
    "            for key in self.reservoir_values.keys():\n",
    "                for i, r in self.all_ages.iterrows():\n",
    "                    if (self.all_ages.at[i, 'coreid'] == key) and ('14C' in self.all_ages.at[i, 'material_category']):\n",
    "                        self.all_ages.at[i, 'reservoir_age'] = self.reservoir_values[key][0]\n",
    "                        self.all_ages.at[i, 'reservoir_error'] = self.reservoir_values[key][1]\n",
    "                self.dttp = 'Yes' ## Needs to be more sophisticated for multiple sediment cores, to answer which core had a transformation\n",
    "            if bool(self.reservoir_values) == False:\n",
    "                self.dttp = 'No' \n",
    "        elif which == 'bulk':\n",
    "            for key in self.reservoir_values.keys():\n",
    "                for i, r in self.all_ages.iterrows():\n",
    "                    if (self.all_ages.at[i, 'coreid'] == key) and ('14C sediment' in self.all_ages.at[i, 'material_category']):\n",
    "                        self.all_ages.at[i, 'reservoir_age'] = self.reservoir_values[key][0]\n",
    "                        self.all_ages.at[i, 'reservoir_error'] = self.reservoir_values[key][1]\n",
    "                self.dttp = 'Yes' ## Needs to be more sophisticated for multiple sediment cores, to answer which core had a transformation\n",
    "            if bool(self.reservoir_values) == False:\n",
    "                self.dttp = 'No' \n",
    "        else:\n",
    "            self.dttp = 'No' \n",
    "        ### Check for logic, if age and reservoir effect are smaller than current date - this is important for Bchron\n",
    "        for i, r in self.all_ages.iterrows():\n",
    "            if ((float(self.all_ages.at[i, 'age']) - float(self.all_ages.at[i, 'reservoir_age'])) < (1950 - datetime.datetime.now().year)) and (self.all_ages.at[i,'compositedepth'] <= 1):\n",
    "                self.all_ages.at[i, 'reservoir_age'] = float(self.all_ages.at[i, 'age']) - float(self.all_ages[(self.all_ages.coreid == self.all_ages.at[i, 'coreid'])&(self.all_ages.labid.str.contains('_Surface'))]['age'])\n",
    "                self.all_ages.at[i, 'reservoir_error'] = 0\n",
    "            elif ((float(self.all_ages.at[i, 'age']) - float(self.all_ages.at[i, 'reservoir_age'])) < (1950 - datetime.datetime.now().year)) and (self.all_ages.at[i,'compositedepth'] > 1):\n",
    "                self.all_ages.at[i, 'reservoir_age'] = 0\n",
    "                self.all_ages.at[i, 'reservoir_error'] = 0\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        return self.all_ages\n",
    "\n",
    "#### OxCal\n",
    "#class AggDataOxCal(object):\n",
    "#    def __init__(self, OxCal_core_results, dttp):\n",
    "#        self.OxCal_core_results = OxCal_core_results\n",
    "#        self.dttp = dttp\n",
    "#    \n",
    "#    def __confidence_intervals(self, g):\n",
    "#        \"\"\"\n",
    "#        Helper function to get basic statistics (median, mean, 1-sigma range, 2-sigma range)\n",
    "#        \n",
    "#        returns:\n",
    "#        @median: median value of input data\n",
    "#        @mean:  mean value of input data\n",
    "#        @two_sigma_lo: lower boundary value of 2-sigma range of input data\n",
    "#        @one_sigma_lo: lower boundary value of 1-sigma range of input data\n",
    "#        @one_sigma_hi: upper boundary value of 1-sigma range of input data\n",
    "#        @two_sigma_hi: upper boundary value of 2-sigma range of input data\n",
    "#        \"\"\"\n",
    "#        median = g.median()\n",
    "#        mean = g.mean()\n",
    "#        two_sigma_hi = g.quantile(q = 0.954, interpolation = 'nearest') \n",
    "#        two_sigma_lo = g.quantile(q = 0.046, interpolation = 'nearest')\n",
    "#        one_sigma_hi = g.quantile(q = 0.683, interpolation = 'nearest') \n",
    "#        one_sigma_lo = g.quantile(q = 0.317, interpolation = 'nearest')\n",
    "#        return median, mean, two_sigma_lo, one_sigma_lo, one_sigma_hi, two_sigma_hi\n",
    "#    \n",
    "#    def __sort_data(self, data):\n",
    "#        \"\"\"\n",
    "#        Helper function to sort MeasurementID\n",
    "#        \n",
    "#        returns:\n",
    "#        @data: dataframe with sorted MeasurementID, where composite depth is sorted numeric not as string\n",
    "#        \"\"\"\n",
    "#        data[['coreid','compositedepth']] = data['measurementid'].str.split(' ', n = 1, expand = True)\n",
    "#        data = data.astype(dtype = {'compositedepth' : float}).sort_values(by = ['coreid','compositedepth'], ignore_index = True)\n",
    "#        data.drop(['compositedepth','coreid'], axis = 1, inplace = True)\n",
    "#        return data \n",
    "#        \n",
    "#    def results_agg(self):\n",
    "#        \"\"\"\n",
    "#        Main function to aggregate data\n",
    "#        \n",
    "#        returns:\n",
    "#        @self.age_model_result_OxCal: dataframe holding the results from the aggregation \n",
    "#        @self.OxCal_core_results: altered 10,000 iteration results from OxCal with MeasurementID and model name added\n",
    "#        \"\"\"\n",
    "#        OxCal_core_results = self.OxCal_core_results\n",
    "#        dttp = self.dttp\n",
    "#        ##\n",
    "#        OxCal_core_results.reset_index(inplace = True)\n",
    "#        OxCal\n",
    "#        ##\n",
    "#        self.age_model_result_OxCal = OxCal_core_results.apply(self.__confidence_intervals, axis = 1, result_type='expand')\n",
    "#        self.age_model_result_OxCal.columns = ['modeloutput_median',\n",
    "#                                           'modeloutput_mean',\n",
    "#                                           'lower_2_sigma',\n",
    "#                                           'lower_1_sigma',\n",
    "#                                           'upper_1_sigma',\n",
    "#                                           'upper_2_sigma']\n",
    "#        self.age_model_result_OxCal = self.age_model_result_OxCal.astype(int)\n",
    "#        self.age_model_result_OxCal = self.age_model_result_OxCal.reset_index()\n",
    "#        self.age_model_result_OxCal = self.age_model_result_OxCal.rename(columns={\"index\": \"measurementid\"})\n",
    "#        self.age_model_result_OxCal = self.__sort_data(self.age_model_result_OxCal)\n",
    "#        self.age_model_result_OxCal.insert(7, 'model_name', 'OxCal', True)\n",
    "#        self.age_model_result_OxCal.insert(8, 'preselection', dttp, True)\n",
    "#        ###\n",
    "#        self.OxCal_core_results.reset_index(inplace = True)\n",
    "#        self.OxCal_core_results['model_name'] = 'OxCal'\n",
    "#        self.OxCal_core_results.rename(columns={\"index\": \"measurementid\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook aggregate_data.ipynb to script\n",
      "[NbConvertApp] Writing 38253 bytes to aggregate_data.py\n"
     ]
    }
   ],
   "source": [
    "#!jupyter nbconvert --to script aggregate_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
